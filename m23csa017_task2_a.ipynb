{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logging():\n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "setup_logging()\n",
    "logger = logging.getLogger(\"Main\")\n",
    "\n",
    "output_dir = \"../output/task2a\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "metadata_path = \"../data/UrbanSound8K/metadata/UrbanSound8K.csv\"\n",
    "audio_dir = \"../data/UrbanSound8K/audio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-02 22:18:54,373 - INFO - Metadata loaded successfully.\n",
      "2025-02-02 22:18:54,374 - INFO - Classes found: ['air_conditioner', 'car_horn', 'children_playing', 'dog_bark', 'drilling', 'engine_idling', 'gun_shot', 'jackhammer', 'siren', 'street_music']\n",
      "2025-02-02 22:18:54,377 - INFO - Train samples: 6985, Test samples: 1747\n"
     ]
    }
   ],
   "source": [
    "def load_metadata(metadata_path):\n",
    "    metadata = pd.read_csv(metadata_path)\n",
    "    logger.info(\"Metadata loaded successfully.\")\n",
    "    return metadata\n",
    "\n",
    "metadata = load_metadata(metadata_path)\n",
    "\n",
    "le = LabelEncoder()\n",
    "metadata[\"encoded_class\"] = le.fit_transform(metadata[\"class\"])\n",
    "logger.info(f\"Classes found: {list(le.classes_)}\")\n",
    "\n",
    "\n",
    "train_data, test_data = train_test_split(metadata, test_size=0.2, random_state=42, stratify=metadata[\"encoded_class\"])\n",
    "logger.info(f\"Train samples: {len(train_data)}, Test samples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hann_window(N):\n",
    "    n = np.arange(N)\n",
    "    return 0.5 * (1 - np.cos(2 * np.pi * n / (N - 1)))\n",
    "\n",
    "def hamming_window(N):\n",
    "    n = np.arange(N)\n",
    "    return 0.54 - 0.46 * np.cos(2 * np.pi * n / (N - 1))\n",
    "\n",
    "def rectangular_window(N):\n",
    "    return np.ones(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-02 22:18:54,478 - INFO - Window functions plot saved to ../output/task2a/window_functions.png\n"
     ]
    }
   ],
   "source": [
    "def plot_window_functions(window_funcs, N=1024, output_path=os.path.join(output_dir, \"window_functions.png\")):\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    x = np.arange(N)\n",
    "    for name, func in window_funcs:\n",
    "        w = func(N)\n",
    "        plt.plot(x, w, label=name)\n",
    "    plt.title(\"Window Functions\")\n",
    "    plt.xlabel(\"Sample\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "    logger.info(f\"Window functions plot saved to {output_path}\")\n",
    "\n",
    "plot_window_functions([(\"Hann\", hann_window), (\"Hamming\", hamming_window), (\"Rectangular\", rectangular_window)], N=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-02 22:40:04,245 - INFO - Audio analysis plot saved to ../output/task2a/audio_analysis.png\n",
      "2025-02-02 22:40:04,510 - INFO - Spectrogram saved to ../output/task2a/spectrogram.png\n"
     ]
    }
   ],
   "source": [
    "def compute_stft(y, window_func, N=1024, hop_length=512):\n",
    "    window = window_func(N)\n",
    "    return librosa.stft(y, n_fft=N, hop_length=hop_length, window=window)\n",
    "\n",
    "\n",
    "def extract_features(file_path, window_func, N=1024, hop_length=256, n_mfcc=40):\n",
    "\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=None)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "    D = compute_stft(y, window_func, N, hop_length)\n",
    "    S = np.abs(D)\n",
    "    \n",
    "    mfcc = librosa.feature.mfcc(S=librosa.power_to_db(S**2), sr=sr, n_mfcc=n_mfcc)\n",
    "    return np.mean(mfcc.T, axis=0)\n",
    "\n",
    "def process_features(data, window_func, N=1024, hop_length=512, n_mfcc=40):\n",
    "\n",
    "    features = []\n",
    "    labels = []\n",
    "    for _, row in tqdm(data.iterrows(), total=len(data), desc=\"Extracting features\"):\n",
    "        file_path = os.path.join(audio_dir, f\"fold{row['fold']}\", row[\"slice_file_name\"])\n",
    "        feat = extract_features(file_path, window_func, N, hop_length, n_mfcc)\n",
    "        if feat is not None:\n",
    "            features.append(feat)\n",
    "            labels.append(row[\"encoded_class\"])\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "\n",
    "\n",
    "def estimate_noise_floor(signal, frame_length=1024, hop_length=512):\n",
    "    \n",
    "    frames = librosa.util.frame(signal, frame_length=frame_length, hop_length=hop_length)\n",
    "    \n",
    "    frame_power = np.mean(frames**2, axis=0)\n",
    "    \n",
    "    noise_floor = np.min(frame_power)\n",
    "    return noise_floor\n",
    "\n",
    "def compute_snr_comparison(signal, window_func, N):  \n",
    "    noise_floor = estimate_noise_floor(signal)\n",
    "    \n",
    "    signal_power = np.mean(signal ** 2)\n",
    "    original_snr = 10 * np.log10(signal_power / noise_floor) if noise_floor > 0 else np.inf\n",
    "    \n",
    "    \n",
    "    window = window_func(len(signal))\n",
    "    windowed_signal = signal * window\n",
    "    \n",
    "    \n",
    "    windowed_power = np.mean(windowed_signal ** 2)\n",
    "    windowed_snr = 10 * np.log10(windowed_power / noise_floor) if noise_floor > 0 else np.inf\n",
    "    \n",
    "    return original_snr, windowed_snr\n",
    "\n",
    "def compute_rmse(original, windowed):\n",
    "\n",
    "    scale_factor = np.sqrt(np.sum(original**2) / np.sum(windowed**2))\n",
    "    windowed_normalized = windowed * scale_factor\n",
    "    return np.sqrt(np.mean((original - windowed_normalized) ** 2))\n",
    "\n",
    "def compute_cumulative_error(original, windowed):\n",
    "    \n",
    "    time_error = np.sum(np.abs(original - windowed))\n",
    "    \n",
    "    orig_fft = np.fft.fft(original)\n",
    "    wind_fft = np.fft.fft(windowed)\n",
    "    freq_error = np.sum(np.abs(np.abs(orig_fft) - np.abs(wind_fft)))\n",
    "    \n",
    "    return {\n",
    "        'time_domain_error': time_error,\n",
    "        'frequency_domain_error': freq_error,\n",
    "        'total_error': time_error + freq_error\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_spectral_leakage(window_func, N, fs=22050):\n",
    "    \n",
    "    t = np.arange(N) / fs\n",
    "    bin_spacing = fs / N\n",
    "    freq = 5.5 * bin_spacing  \n",
    "    x = np.sin(2 * np.pi * freq * t)\n",
    "\n",
    "    w = window_func(N)\n",
    "    w /= np.sum(w)  \n",
    "    xw = x * w\n",
    "    \n",
    "    X = np.fft.fft(xw, n=8 * N)\n",
    "    X_mag = np.abs(X) ** 2 \n",
    "\n",
    "    peak_index = np.argmax(X_mag)\n",
    "    n_bins = X_mag.size    \n",
    "    \n",
    "    main_lobe_start = max(0, peak_index - 5)\n",
    "    main_lobe_end = min(n_bins, peak_index + 5)\n",
    "    \n",
    "    main_lobe_energy = np.sum(X_mag[main_lobe_start:main_lobe_end])\n",
    "    total_energy = np.sum(X_mag)\n",
    "    leakage = 1 - (main_lobe_energy / total_energy)\n",
    "    \n",
    "    return leakage\n",
    "\n",
    "\n",
    "def compute_window_metrics(file_path, window_func, N, fs_target=None):\n",
    "\n",
    "    x, sr = librosa.load(file_path, sr=None)\n",
    "    if fs_target is None:\n",
    "        fs_target = sr\n",
    "    \n",
    "    \n",
    "    if len(x) < N:\n",
    "        x = np.pad(x, (0, N - len(x)), mode='constant')\n",
    "    else:\n",
    "        x = x[:N]\n",
    "    \n",
    "    w = window_func(N)\n",
    "    xw = x * w\n",
    "    \n",
    "    original_snr, windowed_snr = compute_snr_comparison(x, window_func, N)\n",
    "    snr_difference = original_snr - windowed_snr\n",
    "    \n",
    "    \n",
    "    rmse_value = compute_rmse(x, xw)\n",
    "    \n",
    "    \n",
    "    error_metrics = compute_cumulative_error(x, xw)\n",
    "    \n",
    "    \n",
    "    leakage = compute_spectral_leakage(window_func, N, fs=fs_target)\n",
    "    \n",
    "    \n",
    "    time_resolution = N / fs_target\n",
    "    frequency_resolution = fs_target / N\n",
    "    \n",
    "    return {\n",
    "        'original_snr': original_snr,\n",
    "        'windowed_snr': windowed_snr,\n",
    "        'snr_difference': snr_difference,\n",
    "        'rmse': rmse_value,\n",
    "        'cumulative_error': error_metrics,\n",
    "        'spectral_leakage': leakage,\n",
    "        'time_resolution': time_resolution,\n",
    "        'frequency_resolution': frequency_resolution\n",
    "    }\n",
    "\n",
    "\n",
    "#sample for plottign the spectrogram and mfcc\n",
    "sample_row = train_data.iloc[0]\n",
    "sample_audio_path = os.path.join(audio_dir, f\"fold{sample_row['fold']}\", sample_row[\"slice_file_name\"])\n",
    "\n",
    "\n",
    "def plot_spectrogram(file_path, window_func, N=1024, hop_length=512, output_path=\"spectrogram.png\"):\n",
    "\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    D = compute_stft(y, window_func, N, hop_length)\n",
    "    S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(S_db, sr=sr, hop_length=hop_length, x_axis=\"time\", y_axis=\"log\", cmap='viridis')\n",
    "    plt.colorbar(format=\"%+2.0f dB\")\n",
    "    plt.title(f\"Spectrogram (N={N}, hop_length={hop_length})\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "    logger.info(f\"Spectrogram saved to {output_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_audio_analysis(file_path, window_func, N=1024, hop_length=512, n_mfcc=40, output_path=\"audio_analysis.png\"):\n",
    "    \n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    D = compute_stft(y, window_func, N, hop_length)\n",
    "    S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "    mfcc = librosa.feature.mfcc(S=librosa.power_to_db(np.abs(D)**2), sr=sr, n_mfcc=n_mfcc)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    \n",
    "    img1 = librosa.display.specshow(S_db, sr=sr, hop_length=hop_length, x_axis=\"time\", y_axis=\"log\", ax=ax[0], cmap='viridis')\n",
    "    ax[0].set_title(f\"Spectrogram (N={N}, hop_length={hop_length})\")\n",
    "    fig.colorbar(img1, ax=ax[0], format=\"%+2.0f dB\")\n",
    "    \n",
    "    \n",
    "    img2 = librosa.display.specshow(mfcc, sr=sr, x_axis=\"time\", ax=ax[1], cmap='viridis')\n",
    "    ax[1].set_title(f\"MFCC (n_mfcc={n_mfcc})\")\n",
    "    fig.colorbar(img2, ax=ax[1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "    logger.info(f\"Audio analysis plot saved to {output_path}\")\n",
    "\n",
    "\n",
    "plot_audio_analysis(sample_audio_path, hann_window, N=1024, hop_length=512, n_mfcc=40, output_path=os.path.join(output_dir, \"audio_analysis.png\"))\n",
    "plot_spectrogram(sample_audio_path, hann_window, N=1024, hop_length=512, output_path=os.path.join(output_dir, \"spectrogram.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(AudioClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(32, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def plot_training_curves(train_losses, val_losses, window_name, output_dir, params_str):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label=\"Training Loss\")\n",
    "    plt.plot(val_losses, label=\"Validation Loss\")\n",
    "    plt.title(f\"Loss Curves - {window_name}\\n{params_str}\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    output_path = os.path.join(output_dir, f\"loss_curve_{window_name}_{params_str}.png\")\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "    logger.info(f\"Loss curve saved to {output_path}\")\n",
    "\n",
    "\n",
    "def train_and_evaluate_nn(X_train, X_test, y_train, y_test, window_name,\n",
    "                          num_epochs=20, batch_size=32, learning_rate=0.001, val_split=0.2):\n",
    "    logger.info(f\"Training and evaluating NN model for {window_name}\")\n",
    "    \n",
    "    \n",
    "    X_train_final, X_val, y_train_final, y_val = train_test_split(X_train, y_train, test_size=val_split, random_state=42, stratify=y_train)\n",
    "    \n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    X_train_tensor = torch.tensor(X_train_final, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train_final, dtype=torch.long)\n",
    "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "    y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "    \n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    \n",
    "    input_dim = X_train.shape[1]\n",
    "    num_classes = len(np.unique(y_train))\n",
    "    model = AudioClassifier(input_dim, num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for batch_features, batch_labels in train_loader:\n",
    "            batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_features)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * batch_features.size(0)\n",
    "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        \n",
    "        \n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_features, batch_labels in val_loader:\n",
    "                batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "                outputs = model(batch_features)\n",
    "                loss = criterion(outputs, batch_labels)\n",
    "                running_val_loss += loss.item() * batch_features.size(0)\n",
    "        epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        \n",
    "        logger.info(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}\")\n",
    "    \n",
    "    \n",
    "    params_str = f\"epochs{num_epochs}_bs{batch_size}\"\n",
    "    plot_training_curves(train_losses, val_losses, window_name, output_dir, params_str)\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test_tensor.to(device))\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "    y_pred = predicted.cpu().numpy()\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    logger.info(f\"Test Accuracy with {window_name}: {acc:.4f}\")\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    logger.info(f\"Classification Report for {window_name}:\\n{report}\")\n",
    "    \n",
    "    #confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    plt.title(f\"Confusion Matrix - {window_name}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    cm_path = os.path.join(output_dir, f\"confusion_matrix_{window_name}.png\")\n",
    "    plt.savefig(cm_path)\n",
    "    plt.close()\n",
    "    logger.info(f\"Confusion matrix saved to {cm_path}\")\n",
    "    \n",
    "    return model, acc, json.dumps(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-02 22:18:55,210 - INFO - Evaluating: Hann_N1024_hop512_mfcc40\n",
      "2025-02-02 22:18:55,215 - INFO - Metrics for Hann_N1024_hop512_mfcc40 -- SNR Diff: 3.30 dB, RMSE: 0.0202, Spectral Leakage: 0.6458, Time Res: 0.0213s, Freq Res: 46.88Hz\n",
      "Extracting features: 100%|██████████| 6985/6985 [00:43<00:00, 160.77it/s]\n",
      "Extracting features: 100%|██████████| 1747/1747 [00:10<00:00, 165.12it/s]\n",
      "2025-02-02 22:19:49,249 - INFO - Training and evaluating NN model for Hann_N1024_hop512_mfcc40\n",
      "2025-02-02 22:19:51,559 - INFO - Epoch [1/20], Train Loss: 2.4560, Val Loss: 1.6460\n",
      "2025-02-02 22:19:53,737 - INFO - Epoch [2/20], Train Loss: 1.5586, Val Loss: 1.5123\n",
      "2025-02-02 22:19:55,975 - INFO - Epoch [3/20], Train Loss: 1.4270, Val Loss: 1.3554\n",
      "2025-02-02 22:19:58,202 - INFO - Epoch [4/20], Train Loss: 1.3151, Val Loss: 1.3953\n",
      "2025-02-02 22:20:00,389 - INFO - Epoch [5/20], Train Loss: 1.2674, Val Loss: 1.2480\n",
      "2025-02-02 22:20:02,618 - INFO - Epoch [6/20], Train Loss: 1.2073, Val Loss: 1.1519\n",
      "2025-02-02 22:20:04,853 - INFO - Epoch [7/20], Train Loss: 1.1203, Val Loss: 1.1504\n",
      "2025-02-02 22:20:07,016 - INFO - Epoch [8/20], Train Loss: 1.0817, Val Loss: 1.1253\n",
      "2025-02-02 22:20:09,230 - INFO - Epoch [9/20], Train Loss: 1.0624, Val Loss: 1.0834\n",
      "2025-02-02 22:20:11,512 - INFO - Epoch [10/20], Train Loss: 1.0308, Val Loss: 1.0665\n",
      "2025-02-02 22:20:13,688 - INFO - Epoch [11/20], Train Loss: 0.9901, Val Loss: 1.0223\n",
      "2025-02-02 22:20:15,876 - INFO - Epoch [12/20], Train Loss: 0.9758, Val Loss: 1.0351\n",
      "2025-02-02 22:20:18,156 - INFO - Epoch [13/20], Train Loss: 0.9517, Val Loss: 1.0754\n",
      "2025-02-02 22:20:20,428 - INFO - Epoch [14/20], Train Loss: 0.9222, Val Loss: 1.0230\n",
      "2025-02-02 22:20:22,708 - INFO - Epoch [15/20], Train Loss: 0.9033, Val Loss: 0.9778\n",
      "2025-02-02 22:20:25,022 - INFO - Epoch [16/20], Train Loss: 0.8972, Val Loss: 1.0183\n",
      "2025-02-02 22:20:27,271 - INFO - Epoch [17/20], Train Loss: 0.8742, Val Loss: 0.9245\n",
      "2025-02-02 22:20:29,393 - INFO - Epoch [18/20], Train Loss: 0.8320, Val Loss: 0.9309\n",
      "2025-02-02 22:20:30,876 - INFO - Epoch [19/20], Train Loss: 0.8329, Val Loss: 0.9272\n",
      "2025-02-02 22:20:33,151 - INFO - Epoch [20/20], Train Loss: 0.8087, Val Loss: 0.9291\n",
      "2025-02-02 22:20:33,233 - INFO - Loss curve saved to ../output/task2a/loss_curve_Hann_N1024_hop512_mfcc40_epochs20_bs32.png\n",
      "2025-02-02 22:20:33,237 - INFO - Test Accuracy with Hann_N1024_hop512_mfcc40: 0.6835\n",
      "2025-02-02 22:20:33,241 - INFO - Classification Report for Hann_N1024_hop512_mfcc40:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.85      0.69       200\n",
      "           1       0.65      0.48      0.55        86\n",
      "           2       0.57      0.71      0.63       200\n",
      "           3       0.77      0.41      0.54       200\n",
      "           4       0.72      0.81      0.76       200\n",
      "           5       0.78      0.69      0.73       200\n",
      "           6       0.49      0.41      0.45        75\n",
      "           7       0.89      0.90      0.90       200\n",
      "           8       0.65      0.81      0.72       186\n",
      "           9       0.71      0.48      0.58       200\n",
      "\n",
      "    accuracy                           0.68      1747\n",
      "   macro avg       0.68      0.66      0.65      1747\n",
      "weighted avg       0.70      0.68      0.68      1747\n",
      "\n",
      "2025-02-02 22:20:33,435 - INFO - Confusion matrix saved to ../output/task2a/confusion_matrix_Hann_N1024_hop512_mfcc40.png\n",
      "2025-02-02 22:20:33,436 - INFO - Evaluating: Hamming_N1024_hop512_mfcc40\n",
      "2025-02-02 22:20:33,440 - INFO - Metrics for Hamming_N1024_hop512_mfcc40 -- SNR Diff: 3.11 dB, RMSE: 0.0180, Spectral Leakage: 0.6232, Time Res: 0.0213s, Freq Res: 46.88Hz\n",
      "Extracting features: 100%|██████████| 6985/6985 [00:43<00:00, 161.83it/s]\n",
      "Extracting features: 100%|██████████| 1747/1747 [00:10<00:00, 165.89it/s]\n",
      "2025-02-02 22:21:27,141 - INFO - Training and evaluating NN model for Hamming_N1024_hop512_mfcc40\n",
      "2025-02-02 22:21:29,359 - INFO - Epoch [1/20], Train Loss: 2.8532, Val Loss: 1.6480\n",
      "2025-02-02 22:21:31,603 - INFO - Epoch [2/20], Train Loss: 1.5962, Val Loss: 1.4804\n",
      "2025-02-02 22:21:33,858 - INFO - Epoch [3/20], Train Loss: 1.4408, Val Loss: 1.3718\n",
      "2025-02-02 22:21:36,133 - INFO - Epoch [4/20], Train Loss: 1.3382, Val Loss: 1.3202\n",
      "2025-02-02 22:21:38,302 - INFO - Epoch [5/20], Train Loss: 1.2560, Val Loss: 1.2395\n",
      "2025-02-02 22:21:40,554 - INFO - Epoch [6/20], Train Loss: 1.1812, Val Loss: 1.1768\n",
      "2025-02-02 22:21:42,802 - INFO - Epoch [7/20], Train Loss: 1.1216, Val Loss: 1.1260\n",
      "2025-02-02 22:21:45,064 - INFO - Epoch [8/20], Train Loss: 1.0647, Val Loss: 1.1033\n",
      "2025-02-02 22:21:47,233 - INFO - Epoch [9/20], Train Loss: 1.0152, Val Loss: 1.0730\n",
      "2025-02-02 22:21:49,413 - INFO - Epoch [10/20], Train Loss: 0.9872, Val Loss: 1.0987\n",
      "2025-02-02 22:21:51,583 - INFO - Epoch [11/20], Train Loss: 0.9541, Val Loss: 1.0748\n",
      "2025-02-02 22:21:53,780 - INFO - Epoch [12/20], Train Loss: 0.9225, Val Loss: 1.0773\n",
      "2025-02-02 22:21:55,949 - INFO - Epoch [13/20], Train Loss: 0.8932, Val Loss: 1.0186\n",
      "2025-02-02 22:21:58,128 - INFO - Epoch [14/20], Train Loss: 0.8606, Val Loss: 1.0430\n",
      "2025-02-02 22:22:00,282 - INFO - Epoch [15/20], Train Loss: 0.8539, Val Loss: 0.9560\n",
      "2025-02-02 22:22:02,385 - INFO - Epoch [16/20], Train Loss: 0.8362, Val Loss: 0.9409\n",
      "2025-02-02 22:22:04,507 - INFO - Epoch [17/20], Train Loss: 0.7855, Val Loss: 0.9351\n",
      "2025-02-02 22:22:06,675 - INFO - Epoch [18/20], Train Loss: 0.7720, Val Loss: 0.9942\n",
      "2025-02-02 22:22:08,862 - INFO - Epoch [19/20], Train Loss: 0.7609, Val Loss: 1.0561\n",
      "2025-02-02 22:22:11,020 - INFO - Epoch [20/20], Train Loss: 0.7559, Val Loss: 0.8719\n",
      "2025-02-02 22:22:11,110 - INFO - Loss curve saved to ../output/task2a/loss_curve_Hamming_N1024_hop512_mfcc40_epochs20_bs32.png\n",
      "2025-02-02 22:22:11,114 - INFO - Test Accuracy with Hamming_N1024_hop512_mfcc40: 0.7052\n",
      "2025-02-02 22:22:11,118 - INFO - Classification Report for Hamming_N1024_hop512_mfcc40:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.71      0.77       200\n",
      "           1       0.61      0.53      0.57        86\n",
      "           2       0.73      0.39      0.50       200\n",
      "           3       0.52      0.81      0.64       200\n",
      "           4       0.84      0.79      0.81       200\n",
      "           5       0.67      0.82      0.74       200\n",
      "           6       0.72      0.41      0.53        75\n",
      "           7       0.90      0.91      0.90       200\n",
      "           8       0.82      0.78      0.80       186\n",
      "           9       0.54      0.62      0.58       200\n",
      "\n",
      "    accuracy                           0.71      1747\n",
      "   macro avg       0.72      0.68      0.68      1747\n",
      "weighted avg       0.72      0.71      0.70      1747\n",
      "\n",
      "2025-02-02 22:22:11,324 - INFO - Confusion matrix saved to ../output/task2a/confusion_matrix_Hamming_N1024_hop512_mfcc40.png\n",
      "2025-02-02 22:22:11,325 - INFO - Evaluating: Rectangular_N1024_hop512_mfcc40\n",
      "2025-02-02 22:22:11,329 - INFO - Metrics for Rectangular_N1024_hop512_mfcc40 -- SNR Diff: -0.00 dB, RMSE: 0.0000, Spectral Leakage: 0.5736, Time Res: 0.0213s, Freq Res: 46.88Hz\n",
      "Extracting features: 100%|██████████| 6985/6985 [00:42<00:00, 164.04it/s]\n",
      "Extracting features: 100%|██████████| 1747/1747 [00:10<00:00, 166.47it/s]\n",
      "2025-02-02 22:23:04,410 - INFO - Training and evaluating NN model for Rectangular_N1024_hop512_mfcc40\n",
      "2025-02-02 22:23:05,086 - INFO - Epoch [1/20], Train Loss: 2.4548, Val Loss: 1.6951\n",
      "2025-02-02 22:23:05,675 - INFO - Epoch [2/20], Train Loss: 1.5511, Val Loss: 1.4649\n",
      "2025-02-02 22:23:06,245 - INFO - Epoch [3/20], Train Loss: 1.4035, Val Loss: 1.3876\n",
      "2025-02-02 22:23:06,927 - INFO - Epoch [4/20], Train Loss: 1.2983, Val Loss: 1.2579\n",
      "2025-02-02 22:23:07,455 - INFO - Epoch [5/20], Train Loss: 1.2304, Val Loss: 1.2229\n",
      "2025-02-02 22:23:08,182 - INFO - Epoch [6/20], Train Loss: 1.1632, Val Loss: 1.3088\n",
      "2025-02-02 22:23:08,711 - INFO - Epoch [7/20], Train Loss: 1.1172, Val Loss: 1.2550\n",
      "2025-02-02 22:23:09,439 - INFO - Epoch [8/20], Train Loss: 1.0534, Val Loss: 1.1247\n",
      "2025-02-02 22:23:09,968 - INFO - Epoch [9/20], Train Loss: 1.0186, Val Loss: 1.1317\n",
      "2025-02-02 22:23:10,697 - INFO - Epoch [10/20], Train Loss: 0.9949, Val Loss: 1.1091\n",
      "2025-02-02 22:23:11,228 - INFO - Epoch [11/20], Train Loss: 0.9438, Val Loss: 1.0534\n",
      "2025-02-02 22:23:11,957 - INFO - Epoch [12/20], Train Loss: 0.9348, Val Loss: 1.0759\n",
      "2025-02-02 22:23:12,485 - INFO - Epoch [13/20], Train Loss: 0.8885, Val Loss: 1.0615\n",
      "2025-02-02 22:23:13,215 - INFO - Epoch [14/20], Train Loss: 0.8669, Val Loss: 1.1057\n",
      "2025-02-02 22:23:13,745 - INFO - Epoch [15/20], Train Loss: 0.8677, Val Loss: 0.9676\n",
      "2025-02-02 22:23:14,474 - INFO - Epoch [16/20], Train Loss: 0.8234, Val Loss: 0.9749\n",
      "2025-02-02 22:23:15,002 - INFO - Epoch [17/20], Train Loss: 0.8003, Val Loss: 0.9298\n",
      "2025-02-02 22:23:15,730 - INFO - Epoch [18/20], Train Loss: 0.7874, Val Loss: 0.9246\n",
      "2025-02-02 22:23:16,266 - INFO - Epoch [19/20], Train Loss: 0.7638, Val Loss: 0.9676\n",
      "2025-02-02 22:23:16,470 - INFO - Epoch [20/20], Train Loss: 0.7667, Val Loss: 0.9749\n",
      "2025-02-02 22:23:16,550 - INFO - Loss curve saved to ../output/task2a/loss_curve_Rectangular_N1024_hop512_mfcc40_epochs20_bs32.png\n",
      "2025-02-02 22:23:16,552 - INFO - Test Accuracy with Rectangular_N1024_hop512_mfcc40: 0.6880\n",
      "2025-02-02 22:23:16,557 - INFO - Classification Report for Rectangular_N1024_hop512_mfcc40:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81       200\n",
      "           1       0.67      0.51      0.58        86\n",
      "           2       0.70      0.45      0.54       200\n",
      "           3       0.65      0.64      0.64       200\n",
      "           4       0.67      0.82      0.74       200\n",
      "           5       0.67      0.83      0.74       200\n",
      "           6       0.76      0.37      0.50        75\n",
      "           7       0.88      0.85      0.87       200\n",
      "           8       0.82      0.63      0.72       186\n",
      "           9       0.46      0.65      0.54       200\n",
      "\n",
      "    accuracy                           0.69      1747\n",
      "   macro avg       0.71      0.66      0.67      1747\n",
      "weighted avg       0.70      0.69      0.68      1747\n",
      "\n",
      "2025-02-02 22:23:16,763 - INFO - Confusion matrix saved to ../output/task2a/confusion_matrix_Rectangular_N1024_hop512_mfcc40.png\n",
      "2025-02-02 22:23:16,765 - INFO - Experiment results saved to ../output/task2a/parameter_experiment_results.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = []\n",
    "\n",
    "N_list = [1024]\n",
    "hop_length_list = [512]\n",
    "n_mfcc_list = [40]\n",
    "\n",
    "window_functions = [(\"Hann\", hann_window), (\"Hamming\", hamming_window), (\"Rectangular\", rectangular_window)]\n",
    "\n",
    "\n",
    "for window_name, window_func in window_functions:\n",
    "    for N_val in N_list:\n",
    "        for hop_val in hop_length_list:\n",
    "            for n_mfcc_val in n_mfcc_list:\n",
    "                current_config = f\"N{N_val}_hop{hop_val}_mfcc{n_mfcc_val}\"\n",
    "                current_window_name = f\"{window_name}_{current_config}\"\n",
    "                logger.info(f\"Evaluating: {current_window_name}\")\n",
    "                \n",
    "                \n",
    "                metrics = compute_window_metrics(sample_audio_path, window_func, N_val)\n",
    "                \n",
    "                snr_val = metrics['snr_difference']\n",
    "                rmse_val = metrics['rmse']\n",
    "                leakage_val = metrics['spectral_leakage']\n",
    "                time_res  = metrics['time_resolution']\n",
    "                freq_res  = metrics['frequency_resolution']\n",
    "                \n",
    "                logger.info(f\"Metrics for {current_window_name} -- SNR Diff: {snr_val:.2f} dB, RMSE: {rmse_val:.4f}, \" +\n",
    "                            f\"Spectral Leakage: {leakage_val:.4f}, Time Res: {time_res:.4f}s, Freq Res: {freq_res:.2f}Hz\")\n",
    "                \n",
    "                \n",
    "                X_train_features, y_train_labels = process_features(train_data, window_func, N=N_val, hop_length=hop_val, n_mfcc=n_mfcc_val)\n",
    "                X_test_features, y_test_labels = process_features(test_data, window_func, N=N_val, hop_length=hop_val, n_mfcc=n_mfcc_val)\n",
    "                \n",
    "                \n",
    "                model, acc, report_json = train_and_evaluate_nn(\n",
    "                    X_train_features, X_test_features, y_train_labels, y_test_labels,\n",
    "                    window_name=current_window_name,\n",
    "                    num_epochs=20, batch_size=32, learning_rate=0.001\n",
    "                )\n",
    "                \n",
    "                results.append({\n",
    "                    \"Window\": window_name,\n",
    "                    \"N\": N_val,\n",
    "                    \"hop_length\": hop_val,\n",
    "                    \"n_mfcc\": n_mfcc_val,\n",
    "                    \"SNR (dB)\": snr_val,\n",
    "                    \"RMSE\": rmse_val,\n",
    "                    \"Spectral Leakage\": leakage_val,\n",
    "                    \"Time Resolution (s)\": time_res,\n",
    "                    \"Frequency Resolution (Hz)\": freq_res,\n",
    "                    \"Test Accuracy\": acc,\n",
    "                    \"Report\": report_json\n",
    "                })\n",
    "                \n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_csv_path = os.path.join(output_dir, \"parameter_experiment_results.csv\")\n",
    "results_df.to_csv(results_csv_path, index=False)\n",
    "logger.info(f\"Experiment results saved to {results_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
